import json
import os
import re
import streamlit as st
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain_community.callbacks import StreamlitCallbackHandler

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# custom tools
from src.code_interpreter import CodeInterpreterClient
from tools.code_interpreter import code_interpreter_tool


def get_openai_apikey() -> str:
    """
    OpenAI APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¾ã™ã€‚

    ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯secret.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¾ã™ã€‚

    Returns:
        str: OpenAI APIã‚­ãƒ¼

    Raises:
        ValueError: APIã‚­ãƒ¼ã®å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    try:
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            return api_key

        # secret.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
        secret_path = "secret.json"
        if os.path.exists(secret_path):
            with open(secret_path) as f:
                secret = json.load(f)
                return secret["OPENAI_API_KEY"]
        else:
            raise FileNotFoundError("secret.json file not found")
    except (KeyError, FileNotFoundError) as e:
        raise ValueError(f"Error obtaining API key: {str(e)}")


@st.cache_data
def load_system_prompt(file_path: str) -> str:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€é–¢æ•°
    
    Args:
        file_path (str): ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    
    Returns:
        str: èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹
    """
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()


def csv_upload() -> None:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤ºã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ã™ã‚‹é–¢æ•°"""
    with st.form("csv-upload-form", clear_on_submit=True):
        file = st.file_uploader(label='Upload your CSV hereğŸ˜‡', type='csv')
        submitted = st.form_submit_button("Upload CSV")
        if submitted and file is not None:
            if file.name not in st.session_state.uploaded_files:
                assistant_api_file_id = st.session_state.code_interpreter_client.upload_file(file.read())
                st.session_state.custom_system_prompt += \
                    f"\nã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å: {file.name} (Code Interpreterã§ã®path: /mnt/data/{assistant_api_file_id})\n"
                st.session_state.uploaded_files.append(file.name)
        else:
            st.write("ãƒ‡ãƒ¼ã‚¿åˆ†æã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã­")

    if st.session_state.uploaded_files:
        st.sidebar.markdown("## Uploaded files:")
        for file_name in st.session_state.uploaded_files:
            st.sidebar.markdown(f"- {file_name}")


def initialize_page() -> None:
    """ãƒšãƒ¼ã‚¸ã®åˆæœŸè¨­å®šã‚’è¡Œã†é–¢æ•°"""
    st.set_page_config(page_title="Data Analysis Agent", page_icon="ğŸ¤—")
    st.header("Data Analysis Agent ğŸ¤—", divider='rainbow')
    st.sidebar.title("Options")

    # åˆæœŸåŒ–ãƒœã‚¿ãƒ³ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = []
        st.session_state.code_interpreter_client = CodeInterpreterClient()
        st.session_state.memory = ConversationBufferWindowMemory(
            return_messages=True, memory_key="chat_history", k=10
        )
        st.session_state.custom_system_prompt = load_system_prompt("./prompt/system_prompt.txt")
        st.session_state.uploaded_files = []


def select_model() -> ChatOpenAI:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™é–¢æ•°
    
    Returns:
        ChatOpenAI: é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    models = ("gpt-4o-mini", "gpt-4o")
    model = st.sidebar.radio("Choose a model:", models)
    return ChatOpenAI(api_key=get_openai_apikey(),temperature=0, model_name=model)


def create_agent() -> AgentExecutor:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹é–¢æ•°
    
    Returns:
        AgentExecutor: ä½œæˆã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    tools = [code_interpreter_tool]
    prompt = ChatPromptTemplate.from_messages([
        ("system", st.session_state.custom_system_prompt),
        MessagesPlaceholder(variable_name="chat_history"),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    llm = select_model()
    agent = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(agent=agent, tools=tools, verbose=True, memory=st.session_state.memory)


def parse_response(response: str) -> tuple[str, list[str]]:
    """response ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒãƒ‘ã‚¹ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
    
    Args:
        response (str): ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    
    Returns:
        tuple[str, list[str]]: ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒãƒ‘ã‚¹ã®ã‚¿ãƒ—ãƒ«
    """
    img_pattern = re.compile(r'<img\s+[^>]*?src="([^"]+)"[^>]*?>')
    image_paths = img_pattern.findall(response)
    text = img_pattern.sub('', response).strip()
    return text, image_paths


def display_content(content: str) -> None:
    """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å†…å®¹ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
    
    Args:
        content (str): ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹
    """
    text, image_paths = parse_response(content)
    st.write(text)
    for image_path in image_paths:
        st.image(image_path, caption="")


def main() -> None:
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    initialize_page()
    csv_upload()
    data_analysis_agent = create_agent()

    for msg in st.session_state.memory.chat_memory.messages:
        with st.chat_message(msg.type):
            display_content(msg.content)

    if prompt := st.chat_input(placeholder="åˆ†æã—ãŸã„ã“ã¨ã‚’æ›¸ã„ã¦ã­"):
        st.chat_message("user").write(prompt)
        with st.chat_message("assistant"):
            st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=True)
            response = data_analysis_agent.invoke({'input': prompt}, config=RunnableConfig({'callbacks': [st_cb]}))
            display_content(response["output"])


if __name__ == '__main__':
    main()

