# LLMãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã§ãã‚‹Streamlit chatã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import getpass
import json
import os

import tiktoken
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

# APIã‚­ãƒ¼ã®å–å¾—
def get_apikey(model: str) -> str:
    with open("secret.json") as f:
        secret = json.load(f)
    if model == "gpt-4o mini":
        return secret["OPENAI_API_KEY"]
    elif model == "Claude 3.5 Sonnet":
        return secret["ANTHROPIC_API_KEY"]

# ãƒ¢ãƒ‡ãƒ«ã®æ–™é‡‘æƒ…å ±
MODEL_PRICES = {
    "input": {
        "gpt-4o-mini": 0.15 / 1_000_000,
        "claude-3-5-sonnet-20240620": 3 / 1_000_000
    },
    "output": {
        "gpt-4o-mini": 0.6 / 1_000_000,
        "claude-3-5-sonnet-20240620": 15 / 1_000_000
    }
}

# ç”»é¢ã®åˆæœŸåŒ–
def init_page():
    st.set_page_config(
        page_title="My Great ChatGPT",
        page_icon="ğŸ¤—"
    )
    st.header("My Great ChatGPT ğŸ¤—")
    st.sidebar.title("Options")

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åˆæœŸåŒ–
def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    # clear_button ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã‚„ message_history ãŒã¾ã å­˜åœ¨ã—ãªã„å ´åˆã«åˆæœŸåŒ–
    if clear_button or "message_history" not in st.session_state:
        st.session_state.message_history = [
            ("system", "You are a helpful assistant.")
        ]

# ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
def select_model():
    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
    # åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.01ã¨ã™ã‚‹
    temperature = st.sidebar.slider(
        "Temperature:", min_value=0.0, max_value=1.0, value=0.0, step=0.01)

    models = ("gpt-4o mini", "Claude 3.5 Sonnet")
    model = st.sidebar.radio("Choose a model:", models)
    api_key = get_apikey(model)
    if model == "gpt-4o mini":
        st.session_state.model_name = "gpt-4o-mini"
        return ChatOpenAI(
            api_key=api_key,
            model_name=st.session_state.model_name,
            temperature=temperature
        )
    elif model == "Claude 3.5 Sonnet":
        st.session_state.model_name = "claude-3-5-sonnet-20240620"
        return ChatAnthropic(
            api_key=api_key,
            model_name=st.session_state.model_name,
            temperature=temperature
        )

# chainã®åˆæœŸåŒ–
def init_chain():
    # ãƒã‚§ãƒ¼ãƒ³ã®åˆæœŸåŒ–
    st.session_state.llm = select_model()
    prompt = ChatPromptTemplate.from_messages([
        *st.session_state.message_history,
        ("user", "{user_input}")
    ])

    output_parser = StrOutputParser()
    return prompt | st.session_state.llm | output_parser

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚³ã‚¹ãƒˆè¨ˆç®—
def get_message_counts(text):
    if "gpt" in st.session_state.model_name:
        encoding = tiktoken.encoding_for_model(st.session_state.model_name)
    else:
        encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")  # ä»®ã®ã‚‚ã®ã‚’åˆ©ç”¨
    return len(encoding.encode(text))

def calc_and_display_costs():
    output_cnt = 0
    input_cnt = 0
    for role, message in st.session_state.message_history:
        # tiktokenã§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
        token_cnt = get_message_counts(message)
        if role == "ai":
            output_cnt += token_cnt
        else:
            input_cnt += token_cnt
    # åˆæœŸçŠ¶æ…‹ã§ System Message ã®ã¿ãŒå±¥æ­´ã«å…¥ã£ã¦ã„ã‚‹å ´åˆã¯ã¾ã APIã‚³ãƒ¼ãƒ«ãŒè¡Œã‚ã‚Œã¦ã„ãªã„
    if len(st.session_state.message_history) == 1:
        return
    
    input_cost = input_cnt * MODEL_PRICES["input"][st.session_state.model_name] * input_cnt
    output_cost = output_cnt * MODEL_PRICES["output"][st.session_state.model_name] * output_cnt
    
    cost = output_cost + input_cost

    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${cost:.5f}**")
    st.sidebar.markdown(f"- Input cost: ${input_cost:.5f}")
    st.sidebar.markdown(f"- Output cost: ${output_cost:.5f}")


def main():
    init_page()
    init_messages()
    chain = init_chain()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for role, message in st.session_state.get("message_history", []):
        st.chat_message(role).markdown(message)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.chat_message('user').markdown(user_input)

        # LLMã®è¿”ç­”ã‚’ Streaming è¡¨ç¤ºã™ã‚‹
        with st.chat_message('ai'):
            response = st.write_stream(chain.stream({"user_input": user_input}))

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
        st.session_state.message_history.append(("user", user_input))
        st.session_state.message_history.append(("ai", response))

    # ã‚³ã‚¹ãƒˆã‚’è¨ˆç®—ã—ã¦è¡¨ç¤º
    calc_and_display_costs()


if __name__ == '__main__':
    main()
